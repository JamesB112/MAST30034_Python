{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3 Overview\n",
    "\n",
    "Reminder that Project 1 is due this Friday.\n",
    "\n",
    "## First Half\n",
    "- Linear Regression.\n",
    "- Evaluation Metrics.\n",
    "- Penalized Regression (LASSO and Ridge).\n",
    "- Generalised Linear Models (GLM).\n",
    "- Discussion.\n",
    "\n",
    "## Second Half\n",
    "Revision:\n",
    "- Any code related questions for Python.\n",
    "- (Windows 10 Users) Installing WSL2 (Ubuntu 20.04) for a clean environment.\n",
    "\n",
    "Advanced Content:\n",
    "- Introduction to `PySpark` continued."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T01:33:19.109163Z",
     "start_time": "2021-08-10T01:33:18.461721Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "from statsmodels.formula.api import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T01:33:19.155135Z",
     "start_time": "2021-08-10T01:33:19.110561Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VendorID                   int64\n",
       "tpep_pickup_datetime      object\n",
       "tpep_dropoff_datetime     object\n",
       "passenger_count            int64\n",
       "trip_distance            float64\n",
       "pickup_longitude         float64\n",
       "pickup_latitude          float64\n",
       "RatecodeID                 int64\n",
       "store_and_fwd_flag        object\n",
       "dropoff_longitude        float64\n",
       "dropoff_latitude         float64\n",
       "payment_type               int64\n",
       "fare_amount              float64\n",
       "extra                    float64\n",
       "mta_tax                  float64\n",
       "tip_amount               float64\n",
       "tolls_amount             float64\n",
       "improvement_surcharge    float64\n",
       "total_amount             float64\n",
       "pickupX                  float64\n",
       "pickupY                  float64\n",
       "dropoffX                 float64\n",
       "dropoffY                 float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(\"../data/lab_specific/sample.pkl\")\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, let's try to predict `total_amount` using `fare_amount, tip_amount, toll_amount, trip_distance, VendorID` as predictors.\n",
    "\n",
    "Some things to take note:\n",
    "- `tip_amount` is only valid for `payment_type == 1` (card)\n",
    "- `VendorID` is categorical, with only two possible values (`1` or `2`) so we should make it boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T01:33:19.184123Z",
     "start_time": "2021-08-10T01:33:19.156650Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_amount</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>VendorID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65616</th>\n",
       "      <td>38.68</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.84</td>\n",
       "      <td>5.54</td>\n",
       "      <td>9.88</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65617</th>\n",
       "      <td>45.80</td>\n",
       "      <td>38.5</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.75</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65618</th>\n",
       "      <td>8.75</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65619</th>\n",
       "      <td>23.76</td>\n",
       "      <td>18.5</td>\n",
       "      <td>3.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.73</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65620</th>\n",
       "      <td>6.96</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       total_amount  fare_amount  tip_amount  tolls_amount  trip_distance  \\\n",
       "65616         38.68         30.0        1.84          5.54           9.88   \n",
       "65617         45.80         38.5        6.00          0.00          12.75   \n",
       "65618          8.75          6.0        1.45          0.00           0.80   \n",
       "65619         23.76         18.5        3.96          0.00           4.73   \n",
       "65620          6.96          4.5        1.16          0.00           0.80   \n",
       "\n",
       "       VendorID  \n",
       "65616     False  \n",
       "65617     False  \n",
       "65618      True  \n",
       "65619     False  \n",
       "65620     False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter dataframe\n",
    "COL_FILTER = ['total_amount', 'fare_amount', 'tip_amount', 'tolls_amount', 'trip_distance', 'VendorID']\n",
    "df_filtered = df.loc[df['payment_type'] == 1, COL_FILTER].reset_index(drop=True)\n",
    "\n",
    "# same as df_filtered['VendorID'].astype(bool)\n",
    "df_filtered['VendorID'] = df_filtered['VendorID'] == 1 \n",
    "\n",
    "df_filtered.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We are looking for linear relationships between our chosen response `total_amount`.   \n",
    "- Now I'm not sure what kind of life you've lived, but I'm fairly certain that we can infer that `total_amount` will have a positive linear relationship with `fare_amount`. Let's see a quick plot..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T01:33:19.335179Z",
     "start_time": "2021-08-10T01:33:19.185381Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_filtered[['total_amount', 'fare_amount']].plot.scatter(x='fare_amount', y='total_amount')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, obviously this looks like an overall positive linear relationship.\n",
    "- How might we statistically test this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In R, we would do something like this for (Ordinary) Least Squares:\n",
    "```R\n",
    ">>> fit <- lm(total_amount~fare_amount + tip_amount + tolls_amount + trip_distance + VendorID ,data=dat_fit)\n",
    ">>> summary(fit)\n",
    "```\n",
    "```\n",
    "Call:\n",
    "lm(formula = total_amount ~ fare_amount + tip_amount + tolls_amount +\n",
    "trip_distance + VendorID, data = dat_fit)\n",
    "\n",
    "Residuals:\n",
    "Min     1Q      Median  3Q     Max\n",
    "-1.4727 -0.3295 -0.1528 0.1747 1.7975\n",
    "\n",
    "Coefficients:\n",
    "               Estimate Std. Error t value Pr(>|t|)\n",
    "(Intercept)    1.162154   0.002986 389.194  <2e-16 ***\n",
    "fare_amount    0.993388   0.000315 3153.943 <2e-16 ***\n",
    "tip_amount     1.006511   0.000826 1218.553 <2e-16 ***\n",
    "tolls_amount   0.979325   0.001285 762.428  <2e-16 ***\n",
    "trip_distance  0.011742   0.000963 12.194   <2e-16 ***\n",
    "VendorIDTRUE  -0.003125   0.002914 -1.073    0.283\n",
    "---\n",
    "Signif. codes:\n",
    "0 ^a˘A¨Y***^a˘A´Z 0.001 ^a˘A¨Y**^a˘A´Z 0.01 ^a˘A¨Y*^a˘A´Z 0.05 ^a˘A¨Y.^a˘A´Z 0.1 ^a˘A¨Y ^a˘A´Z 1\n",
    "\n",
    "Residual standard error: 0.362 on 61886 degrees of freedom\n",
    "Multiple R-squared: 0.9994,          Adjusted R-squared: 0.9994\n",
    "F-statistic: 1.953e+07 on 5 and 61886 DF, p-value: < 2.2e-16\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, whatever you can do in R can also done in Python (to an extent).  \n",
    "Documentation Source: https://www.statsmodels.org/dev/generated/statsmodels.formula.api.ols.html?highlight=ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T01:33:19.372649Z",
     "start_time": "2021-08-10T01:33:19.336441Z"
    }
   },
   "outputs": [],
   "source": [
    "fit = ols(formula=\"total_amount ~ fare_amount + tip_amount + tolls_amount + trip_distance + VendorID\",\n",
    "         data=df_filtered).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T01:33:19.387618Z",
     "start_time": "2021-08-10T01:33:19.373753Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           total_amount   R-squared:                       1.000\n",
      "Model:                            OLS   Adj. R-squared:                  1.000\n",
      "Method:                 Least Squares   F-statistic:                 4.113e+07\n",
      "Date:                Tue, 10 Aug 2021   Prob (F-statistic):               0.00\n",
      "Time:                        11:33:19   Log-Likelihood:                 5322.1\n",
      "No. Observations:               65621   AIC:                        -1.063e+04\n",
      "Df Residuals:                   65615   BIC:                        -1.058e+04\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "====================================================================================\n",
      "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "Intercept            1.4654      0.002    791.722      0.000       1.462       1.469\n",
      "VendorID[T.True]    -0.0096      0.002     -5.500      0.000      -0.013      -0.006\n",
      "fare_amount          0.9959      0.000   4687.794      0.000       0.995       0.996\n",
      "tip_amount           1.0054      0.001   1695.304      0.000       1.004       1.007\n",
      "tolls_amount         0.9910      0.001   1148.462      0.000       0.989       0.993\n",
      "trip_distance       -0.0051      0.001     -8.257      0.000      -0.006      -0.004\n",
      "==============================================================================\n",
      "Omnibus:                     6787.253   Durbin-Watson:                   0.413\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             9105.878\n",
      "Skew:                           0.904   Prob(JB):                         0.00\n",
      "Kurtosis:                       3.243   Cond. No.                         43.4\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The table structure is a bit different, though it is identical in value with R's output.  \n",
    "- The coefficient table is the same, but now includes a 95% CI for the beta coefficients.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions:\n",
    "- Is this model good?\n",
    "    - The $R^2$ value is 0.999 which is insanely large. As a rule of thumb, large $R^2$ values indicate a good fit. \n",
    "    - *Perhaps too good of a fit...*\n",
    "    - AIC itself isn't important, however, if we compare it to another model (let's say an alternative model with different features chosen)...\n",
    "    - If we have a hypothesis for a null model ($\\beta=0$) vs our fitted model ($\\beta\\neq0$), then we can look at the `F-statistc = 1.953e+07`. The corresponding p-value of  this F statistic is `0.00`, which is less than $\\alpha=0.05$, so we can conclude that our fitted model is better than a null model. In other words, we reject the null hypothesis and conclude that we believe the intercept parameters to be non-zero.\n",
    "    \n",
    "    \n",
    "- How might we improve this model?\n",
    "    - If we look at the parameters, we may wish to exclude `VendorID[T.True]` as it is not significant with p-value `0.283 > 0.05`. Perhaps we should drop this attribute and fit another model without it.\n",
    "    - Additionally, we can do some feature engineering (run a decision tree and look at the splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T01:33:19.415117Z",
     "start_time": "2021-08-10T01:33:19.388720Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           total_amount   R-squared:                       1.000\n",
      "Model:                            OLS   Adj. R-squared:                  1.000\n",
      "Method:                 Least Squares   F-statistic:                 6.844e+07\n",
      "Date:                Tue, 10 Aug 2021   Prob (F-statistic):               0.00\n",
      "Time:                        11:33:19   Log-Likelihood:                 5273.9\n",
      "No. Observations:               65621   AIC:                        -1.054e+04\n",
      "Df Residuals:                   65617   BIC:                        -1.050e+04\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "Intercept        1.4657      0.002    940.683      0.000       1.463       1.469\n",
      "fare_amount      0.9946      0.000   7184.782      0.000       0.994       0.995\n",
      "tip_amount       1.0047      0.001   1711.771      0.000       1.004       1.006\n",
      "tolls_amount     0.9894      0.001   1173.671      0.000       0.988       0.991\n",
      "==============================================================================\n",
      "Omnibus:                     6960.903   Durbin-Watson:                   0.408\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             9427.364\n",
      "Skew:                           0.924   Prob(JB):                         0.00\n",
      "Kurtosis:                       3.189   Cond. No.                         31.0\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "fitter = ols(formula=\"total_amount ~ fare_amount + tip_amount + tolls_amount\",\n",
    "         data=df_filtered).fit()\n",
    "print(fitter.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have to values of AIC to compare with, which one is better...?\n",
    "- Well, we see a small decrease in AIC and a large decrease in BIC. Hence, we can say that the model without `VendorID` is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T01:33:19.420129Z",
     "start_time": "2021-08-10T01:33:19.416960Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([-10632.271532677914, -10539.899110559505],\n",
       " [-10577.721626403982, -10503.532506376883])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[fit.aic, fitter.aic], [fit.bic, fitter.bic]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Penalized Regression\n",
    "- LASSO (l1) and Ridge (l2) Regression\n",
    "\n",
    "Revise in your own time if you've forgotten (this was covered in MAST30025):\n",
    "- Lecture 4 (variable selection)\n",
    "- LSM topic 5 (`ch05_handout`) slide 141/141\n",
    "- An excellent explanation on Ridge / LASSO: https://www.youtube.com/watch?v=9LNpiiKCQUo (recommended at x1.25 speed)\n",
    "\n",
    "Things you might have forgotten when working with penalized models:\n",
    "- Always good to standardize your data prior to train and test. Most models perform poorly if not standardized prior. \n",
    "- Do not fit your standardizer to test, only to train. You should transform both your train and test though.\n",
    "\n",
    "### LASSO ($\\ell_1$)\n",
    "Quick overview:\n",
    "- LASSO may cause coefficients to be set to 0 by constraining the model.\n",
    "- This is because we put a constraint where the sum of the absolute values of the coefficients must be less than some fixed value. \n",
    "- As such, some coefficients may end up having 0 which is the same as *dropping* the attribute from the model. Notably, features that are collinear (correlated) will result in one of them being reduced to 0 coefficient.\n",
    "- In this sense, it's quite similar to feature selection as you end up with a model that is much more simpler. \n",
    "- However, LASSO does not do well when the feature space is small as you may end up with an over-simplified model, as well as cases where all the features are significant or when coefficients are extremely large. \n",
    "- This is why you might want to standardize your dataset prior to fitting.\n",
    "\n",
    "Solution:\n",
    "- Requires an iterative method to solve $(\\mathbf{y}-X\\beta)^T(\\mathbf{y}-X\\beta) + \\lambda I \\beta$\n",
    "- The $\\ell_1$ (vector normal) comes from the penalty term $\\lambda I \\beta$. Our $\\beta$ term is to the power of 1, hence we have $\\ell_1$.\n",
    "\n",
    "### Ridge ($\\ell_2$)\n",
    "Quick overview:\n",
    "- Also know as the MAP (Maximum a posteriori) estimation.\n",
    "- Aims to lower the scale of the coefficients to avoid overfitting, but does not result in coefficients being 0.\n",
    "- In contrast to LASSO, we put a constrain using the sum of squares that must be lest than a fixed value. \n",
    "- As you might guess, this means we still have several features making it less interpretable than LASSO.\n",
    "- However, Ridge Regression performs best in cases where there may be high multi-colinearity (i.e dependencies between attributes) or high linear correlation between certain attributes,\n",
    "- This is because it reduces variance in exchange for some more bias (consider variance-bias tradeoff).\n",
    "- You must also ensure that we have more observations than attributes (`n > p`) as this penalty method does not drop features, leading to worse predictions. \n",
    "\n",
    "Solution:\n",
    "- Closed-form which can be found by minimising $(\\mathbf{y}-X\\beta)^T(\\mathbf{y}-X\\beta) + \\lambda I \\beta^T\\beta$\n",
    "- The $\\ell_2$ (vector normal) comes from the penalty term $\\lambda I \\beta^T\\beta$. Since the $\\beta$ term is squared, we have $\\ell_2$.\n",
    "- Good to practice and show that minimising the equation above yields the \\\n",
    "\n",
    "### Elastic Net\n",
    "Quick overview:\n",
    "- Combines both Ridge and LASSO into a single model utilising an $\\alpha$ parameter, where $\\alpha=0$ is Ridge and $\\alpha=1$ is LASSO.\n",
    "- Implementation Documentation: https://github.com/civisanalytics/python-glmnet/blob/master/glmnet/linear.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T01:33:19.431122Z",
     "start_time": "2021-08-10T01:33:19.421928Z"
    }
   },
   "outputs": [],
   "source": [
    "yCOLS = ['total_amount']\n",
    "xCOLS = ['fare_amount', 'tip_amount', 'tolls_amount', 'trip_distance', 'VendorID']\n",
    "\n",
    "# standardize (by calculating the zscore) so our data has mean 0 and var 1\n",
    "# alternatively, you can use sklearn's StandardScalar\n",
    "\n",
    "from scipy.stats import zscore\n",
    "df_standard = df_filtered[xCOLS].astype(float).apply(zscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T01:33:19.455115Z",
     "start_time": "2021-08-10T01:33:19.432395Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>VendorID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fare_amount  tip_amount  tolls_amount  trip_distance  VendorID\n",
       "mean      -0.0000      0.0000        0.0000         0.0000    0.0000\n",
       "std        1.0000      1.0000        1.0000         1.0000    1.0000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# format output to 4 decimal places\n",
    "pd.options.display.float_format = '{:,.4f}'.format\n",
    "df_standard.describe().loc[['mean','std']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, `df_standard` has  $\\mu=0, \\sigma=1(=\\sigma^2)$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T01:33:19.753125Z",
     "start_time": "2021-08-10T01:33:19.456506Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glmnet import ElasticNet\n",
    "\n",
    "lasso_fit = ElasticNet(alpha=1)\n",
    "lasso_fit.fit(df_standard.values, df_filtered[yCOLS].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to look at the shrinking parameter $\\lambda$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T01:33:19.756117Z",
     "start_time": "2021-08-10T01:33:19.754205Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best lambda value for LASSO: 0.27198196216152276\n"
     ]
    }
   ],
   "source": [
    "# this can be accessed using the .lambda_best_ method after fitting!\n",
    "print(f'Best lambda value for LASSO: {lasso_fit.lambda_best_[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\lambda$ is computed by using cross validation (iterative approach)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about our coefficients?\n",
    "- https://github.com/civisanalytics/python-glmnet/blob/master/glmnet/linear.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T01:33:19.762624Z",
     "start_time": "2021-08-10T01:33:19.757289Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>17.5665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fare_amount</th>\n",
       "      <td>9.8504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tip_amount</th>\n",
       "      <td>2.1925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tolls_amount</th>\n",
       "      <td>1.0554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trip_distance</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VendorID</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Coefficient\n",
       "Intercept          17.5665\n",
       "fare_amount         9.8504\n",
       "tip_amount          2.1925\n",
       "tolls_amount        1.0554\n",
       "trip_distance       0.0000\n",
       "VendorID            0.0000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(index = ['Intercept'] + xCOLS, \n",
    "             data= [lasso_fit.intercept_] + list(lasso_fit.coef_), \n",
    "             columns = ['Coefficient'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, `trip_distance` and `VendorID` have *shrunk* to 0. You can use `lasso_fit.predict(x)` to the predict a new set of observations by passing through the `x` matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting a GLM (Optional)\n",
    "- Well, this is exactly what some of you will be learning in MAST30027 right now.\n",
    "\n",
    "Let's go through an example:\n",
    "- The `passenger_count` attribute is discrete and non-negative. If we were to predict it, a linear model will not be sufficient. \n",
    "- We know that a Poisson distribution takes in non-negative integer values, so we can use the Poisson family of GLMs to model this. \n",
    "- We will use `total_amount, trip_distance, VendorID` as our regressors.\n",
    "\n",
    "For those of you not taking MAST30027 (ELI5):\n",
    "- GLM's allow us to express relationships in a linear and additive way like normal linear regression.\n",
    "- However, it might be the case that the underlying true relationship is neither linear nor additive. \n",
    "- The transformation is done through a *link function* (in this case, Poisson)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-10T01:33:20.137141Z",
     "start_time": "2021-08-10T01:33:19.764025Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:        passenger_count   No. Observations:                98507\n",
      "Model:                            GLM   Df Residuals:                    98503\n",
      "Model Family:                 Poisson   Df Model:                            3\n",
      "Link Function:                    log   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:            -1.4793e+05\n",
      "Date:                Tue, 10 Aug 2021   Deviance:                       67982.\n",
      "Time:                        11:33:20   Pearson chi2:                 8.34e+04\n",
      "No. Iterations:                     5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "====================================================================================\n",
      "                       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "Intercept            0.7066      0.005    137.411      0.000       0.696       0.717\n",
      "VendorID[T.True]    -0.4021      0.005    -79.627      0.000      -0.412      -0.392\n",
      "total_amount        -0.0001      0.001     -0.258      0.796      -0.001       0.001\n",
      "trip_distance       -0.0003      0.002     -0.163      0.871      -0.004       0.003\n",
      "====================================================================================\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.api import families\n",
    "\n",
    "# convert VendorID to categorical\n",
    "df['VendorID'] = df['VendorID'] == 1\n",
    "\n",
    "fit = glm(formula=\"passenger_count ~ total_amount + trip_distance + VendorID\",\n",
    "         data=df, family=families.Poisson()).fit()\n",
    "\n",
    "print(fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can see that `total_amount` is insignificant (`p-val=0.124>0.05`)\n",
    "- Conclude that the total fare amount does not really affect the number of passengers in a trip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "- What is the Bias-Variance tradeoff with respect to linear models:\n",
    "    - Less parameters = less variance but more bias\n",
    "    - More parameters = more variance but less bias\n",
    "    - The goal depends on the problem, but generally we want an even variance and bias (intersection).\n",
    "\n",
    "\n",
    "- Is using regression on X attribute / specific dataset even a good choice...?\n",
    "    - The answer is yes, it is a good choice *to try*\n",
    "    - BUT also try other methods...\n",
    "    \n",
    "    \n",
    "- What are the pros and cons of stepwise regression?\n",
    "    - Forward Selection (start from nothing and end until significant)\n",
    "    - Backward Elimination (start with everything and end until no more can be removed)\n",
    "    - Not always the best results...\n",
    "    \n",
    "    \n",
    "- What is best subset regression and the pros and cons of it?\n",
    "    - A brute-force like method of fitting *all possible regressions* or *all possible models*\n",
    "    - Unlike stepwise, this method fits all possible models based on the variables specified, so you will get the best model possible\n",
    "    ![test](https://i.kym-cdn.com/photos/images/newsfeed/001/718/138/147.jpg)\n",
    "    \n",
    "    \n",
    "    \n",
    "- What is an assumption we make when we fit linear regression models?\n",
    "    - Well, the data has to be linearly separable. \n",
    "    - Does this also apply to other models too...? (Recall SVM and kernel function which we can use)\n",
    "    - Perhaps another model might suit the dataset... (Trees, Neural Networks, Clustering, etc...)\n",
    "    \n",
    "    \n",
    "- If you were to use a decision tree, how would you compare between two different fits? \n",
    "    - Look at Gini Impurity (probability of an incorrectly classified instance)\n",
    "    \n",
    "\n",
    "- How about baselines or other predictive machine learning models?\n",
    "    - Precision, Recall, Classification Accuracy..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Requisite Tasks for the Apache Spark tutorial\n",
    "\n",
    "## WSL Environment for Windows 10\n",
    "Refer to this guide to get a native Linux terminal in Windows 10:\n",
    "- https://github.com/akiratwang/COMP20003-Setting-Up\n",
    "- Ignore all the `C` related parts, just get Ubuntu installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
